{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T16:25:32.417653600Z",
     "start_time": "2024-04-18T16:25:29.550596300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run trainingUtils.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T16:25:33.291656700Z",
     "start_time": "2024-04-18T16:25:32.409654100Z"
    }
   },
   "id": "b21bb4ea6e77c54c"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class ANNTool():\n",
    "    def __init__(self, input_shape=(128, 128, 3), epochs=100, activation='relu',\n",
    "                 loss='binary_crossentropy', optimizer='adam'):\n",
    "        self.input_shape = input_shape\n",
    "        self.epochs = epochs\n",
    "        self.activation = activation\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.train_inputs = None\n",
    "        self.train_outputs = None\n",
    "\n",
    "    def train_classifier(self, train_inputs, train_outputs, epochs=None, activation=None, loss=None, optimizer=None):\n",
    "        if epochs is not None:\n",
    "            self.epochs = epochs\n",
    "        if activation is not None:\n",
    "            self.activation = activation\n",
    "        if loss is not None:\n",
    "            self.loss = loss\n",
    "        if optimizer is not None:\n",
    "            self.optimizer = optimizer\n",
    "        self.train_inputs = train_inputs\n",
    "        self.train_outputs = train_outputs\n",
    "        classifier = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(shape=self.input_shape),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=self.activation),\n",
    "            tf.keras.layers.Dense(64, activation=self.activation),\n",
    "            tf.keras.layers.Dense(32, activation=self.activation),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        classifier.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "        classifier.fit(train_inputs, train_outputs, epochs=self.epochs)\n",
    "        return classifier\n",
    "\n",
    "    def get_predicted_data(self,test_inputs):\n",
    "        classifier = self.train_classifier(self.train_inputs, self.train_outputs)\n",
    "        computed_outputs = classifier.predict(test_inputs)\n",
    "        computed_outputs = np.round(computed_outputs)\n",
    "        return computed_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T20:30:20.752349900Z",
     "start_time": "2024-04-18T20:30:20.739221200Z"
    }
   },
   "id": "4fbc78aac2231d96"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T20:30:20.884686600Z",
     "start_time": "2024-04-18T20:30:20.882157500Z"
    }
   },
   "id": "ef52202de7438cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def run_hyperparameter_testing_ANN(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    hyperparameters = [\n",
    "        {'epochs': 50, 'activation': 'relu', 'loss': 'binary_crossentropy', 'optimizer': 'adam'},\n",
    "        {'epochs': 100, 'activation': 'relu', 'loss': 'binary_crossentropy', 'optimizer': 'sgd'},\n",
    "        {'epochs': 100, 'activation': 'tanh', 'loss': 'mean_squared_error', 'optimizer': 'adam'},\n",
    "        {'epochs': 50, 'activation': 'tanh', 'loss': 'mean_squared_error', 'optimizer': 'sgd'},\n",
    "        {'epochs': 50, 'activation': 'relu', 'loss': 'mean_squared_error', 'optimizer': 'adam'},\n",
    "        {'epochs': 100, 'activation': 'relu', 'loss': 'mean_squared_error', 'optimizer': 'sgd'},\n",
    "        {'epochs': 50, 'activation': 'tanh', 'loss': 'binary_crossentropy', 'optimizer': 'adam'},\n",
    "        {'epochs': 100, 'activation': 'tanh', 'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
    "    ]\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    test_inputs = np.array(test_inputs)\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    results = []\n",
    "    for config in hyperparameters:\n",
    "        ann_tool = ANNTool()\n",
    "        print(f\"Training with config: {config}\")\n",
    "        model = ann_tool.train_classifier(\n",
    "            train_inputs, train_outputs,\n",
    "            epochs=config['epochs'],\n",
    "            activation=config['activation'],\n",
    "            loss=config['loss'],\n",
    "            optimizer=config['optimizer']\n",
    "        )\n",
    "\n",
    "        predicted_outputs = ann_tool.get_predicted_data(test_inputs)\n",
    "        accuracy = np.mean(predicted_outputs == test_outputs)\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "        results.append((config, accuracy))\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T20:43:42.453717300Z",
     "start_time": "2024-04-18T20:43:42.441191900Z"
    }
   },
   "id": "3a182d328df9e26e"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def with_ANNTool(train_inputs,train_outputs,test_inputs,test_outputs,output_names=['no_sepia','sepia']):\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    test_inputs = np.array(test_inputs)\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    try:\n",
    "        annTool = ANNTool()\n",
    "        annTool.train_classifier(train_inputs[:1], train_outputs[:1])\n",
    "    except Exception as e:\n",
    "        print(\"Error with a single data point:\", e)\n",
    "        print(\"Data point shape:\", train_inputs[:1].shape)\n",
    "        print(\"Label shape:\", train_outputs[:1].shape)\n",
    "\n",
    "    try:\n",
    "        annTool = ANNTool()\n",
    "        annTool.train_classifier(train_inputs, train_outputs)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    # Optionally, add more diagnostic print statements here\n",
    "\n",
    "    computed_outputs=annTool.get_predicted_data(test_inputs)\n",
    "    return computed_outputs\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T20:42:53.803415900Z",
     "start_time": "2024-04-18T20:42:53.800733600Z"
    }
   },
   "id": "793a6bea43e1b8d5"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T20:42:53.968506900Z",
     "start_time": "2024-04-18T20:42:53.964966500Z"
    }
   },
   "id": "8d7c4fcb786a79d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b8d80dd196216bc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
