{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import log, exp\n",
    "from numpy.random import randn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:28.601477200Z",
     "start_time": "2024-04-19T08:18:28.575408400Z"
    }
   },
   "id": "880719291cccbd80"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:28.610447200Z",
     "start_time": "2024-04-19T08:18:28.595869700Z"
    }
   },
   "id": "90d2ba09ce1750ed"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8efdb83628a918"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:28.890912200Z",
     "start_time": "2024-04-19T08:18:28.888960400Z"
    }
   },
   "id": "ab30a0be60c380ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN Class\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4dabf1c1070cf56"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class CNNClass():\n",
    "    def __init__(self, shape=(128, 128, 3), epochs=40, batch_size=32, learning_rate=0.001):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def train_classifier(self, train_inputs, train_outputs,epochs=40, batch_size=32, learning_rate=0.001):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        return self.model.fit(train_inputs, train_outputs, epochs=self.epochs, batch_size=self.batch_size)\n",
    "\n",
    "    def get_predicted_data(self, test_inputs):\n",
    "        return np.round(self.model.predict(test_inputs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:29.226039200Z",
     "start_time": "2024-04-19T08:18:29.219484700Z"
    }
   },
   "id": "72de0fa4650ba8b2"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "class MyCNN:\n",
    "    def __init__(self) -> None:\n",
    "        self.layers = []\n",
    "\n",
    "    def addConvolutionLayer(self, numberOfFilters, filterSize):\n",
    "        height, width = filterSize\n",
    "        filters = [[randn() for i in range(0, width)] for j in range(0, height)]\n",
    "        self.layers.append(\n",
    "            {\"type\": \"convolution\", \"numberOfFilters\": numberOfFilters, \"filter\": filters, \"filterSize\": filterSize})\n",
    "\n",
    "    def addMaxPoolingLayer(self, filterSize):\n",
    "        self.layers.append({\"type\": \"maxPooling\", \"filterSize\": filterSize})\n",
    "\n",
    "    def addFullyConnectedLayer(self, inputSize, outputSize, activationFunction=lambda x: x):\n",
    "        weights = [[randn() for j in range(0, inputSize)] for i in range(0, outputSize)]\n",
    "        self.layers.append({\"type\": \"fullyConnected\", \"weights\": weights, \"activationFunction\": activationFunction})\n",
    "\n",
    "    def _applyLayer(self, input, layer):\n",
    "        type = layer[\"type\"]\n",
    "        if type == \"convolution\":\n",
    "            return self.applyConvolution(layer, input)\n",
    "        elif type == \"maxPooling\":\n",
    "            return self.applyMaxPooling(layer, input)\n",
    "        else:\n",
    "            return self.applyFullyConnected(layer, input)\n",
    "\n",
    "    def applyConvolution(self, layer, input):\n",
    "        height, width, depth = len(input), len(input[0]), len(input[0][0])\n",
    "        filter = layer[\"filter\"]\n",
    "        filterSize = layer[\"filterSize\"]\n",
    "        numberOfFilters = layer[\"numberOfFilters\"]\n",
    "\n",
    "        lineStart = filterSize[0] // 2\n",
    "        lineFinish = height - filterSize[0] // 2\n",
    "\n",
    "        columnStart = filterSize[1] // 2\n",
    "        columnFinish = width - filterSize[1] // 2\n",
    "\n",
    "        result = []\n",
    "        for i in range(lineStart, lineFinish):\n",
    "            result.append([])\n",
    "            for j in range(columnStart, columnFinish):\n",
    "                result[-1].append([])\n",
    "                for k in range(0, numberOfFilters):\n",
    "                    for d in range(0, depth):\n",
    "                        suma = 0\n",
    "                        for h in range(0, filterSize[0]):\n",
    "                            for w in range(0, filterSize[1]):\n",
    "                                suma = suma + filter[h][w] * input[i + h - lineStart][j + w - columnStart][d]\n",
    "                        result[-1][-1].append(suma)\n",
    "        return result\n",
    "\n",
    "    def applyMaxPooling(self, layer, input):\n",
    "        filterSize = layer[\"filterSize\"]\n",
    "        height, width = filterSize[0], filterSize[1]\n",
    "        inputHeight, inputWidth, inputDepth = len(input), len(input[0]), len(input[0][0])\n",
    "\n",
    "        result = []\n",
    "        for i in range(0, inputHeight - height, height):\n",
    "            result.append([])\n",
    "            for j in range(0, inputWidth - width, width):\n",
    "                result[-1].append([])\n",
    "                for d in range(0, inputDepth):\n",
    "                    filterValues = []\n",
    "                    for row in range(i, i + height):\n",
    "                        for col in range(j, j + width):\n",
    "                            filterValues.append(input[row][col][d])\n",
    "                    maxValue = max(filterValues)\n",
    "                    result[-1][-1].append(maxValue)\n",
    "        return result\n",
    "\n",
    "    def inputLinearization(self, input):\n",
    "        if all(isinstance(x, (int, float)) for x in input):\n",
    "            return input\n",
    "        result = []\n",
    "        inputHeight, inputWidth, inputDepth = len(input), len(input[0]), len(input[0][0])\n",
    "        for h in range(0, inputHeight):\n",
    "            for w in range(0, inputWidth):\n",
    "                for d in range(0, inputDepth):\n",
    "                    result.append(input[h][w][d])\n",
    "        return result\n",
    "\n",
    "    def applyFullyConnected(self, layer, input):\n",
    "        linearInput = self.inputLinearization(input)\n",
    "        weights = layer[\"weights\"]\n",
    "        activationFunction = layer[\"activationFunction\"]\n",
    "\n",
    "        expectedInputSize = len(weights[0])\n",
    "        if len(linearInput) != expectedInputSize:\n",
    "            linearInput = linearInput[:expectedInputSize]\n",
    "\n",
    "        result = []\n",
    "        for w in range(0, len(weights)):\n",
    "            value = sum(weights[w][i] * linearInput[i] for i in range(0, len(linearInput)))\n",
    "            computedValue = activationFunction(value)\n",
    "            result.append(computedValue)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def applyAllLayers(self, input):\n",
    "        result = input\n",
    "        for layer in self.layers:\n",
    "            result = self._applyLayer(result, layer)\n",
    "        return result\n",
    "\n",
    "    def balanceWeightsConvolution(self, errors, layer):\n",
    "        learning_rate = 0.0000001\n",
    "        for error in errors:\n",
    "            filter = layer[\"filter\"]\n",
    "            filterSize = layer[\"filterSize\"]\n",
    "            for h in range(0, filterSize[0]):\n",
    "                for w in range(0, filterSize[1]):\n",
    "                    layer[\"filter\"][h][w] = layer[\"filter\"][h][w] - error * learning_rate\n",
    "\n",
    "    def balanceWeigthsFullyConnected(self, errors, layer, inputLine):\n",
    "        learning_rate = 0.0000001\n",
    "        for e in range(0, len(errors)):\n",
    "            result = inputLine\n",
    "            for layer1 in self.layers[:-1]:\n",
    "                result = self._applyLayer(result, layer1)\n",
    "            linearResult = self.inputLinearization(result)\n",
    "\n",
    "            for i in range(0, len(linearResult)):\n",
    "                layer[\"weights\"][e][i] = layer[\"weights\"][e][i] - errors[e] * learning_rate * linearResult[i]\n",
    "\n",
    "    def backpropagation(self, errors, inputLine):\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            type = layer[\"type\"]\n",
    "            if type == \"convolution\":\n",
    "                self.balanceWeightsConvolution(errors, layer)\n",
    "            elif type == \"fullyConnected\":\n",
    "                self.balanceWeigthsFullyConnected(errors, layer, inputLine)\n",
    "\n",
    "    def train(self, input, output, numberOfEpochs=10):\n",
    "        for e in range(0, numberOfEpochs):\n",
    "            loss = 0\n",
    "            for i in range(0, len(input)):\n",
    "                inputLine = input[i]\n",
    "                outputLine = output[i]\n",
    "                result = self.applyAllLayers(inputLine)\n",
    "\n",
    "                if outputLine == \"YES\":\n",
    "                    errors = [1 - result[0], 0 - result[1]]\n",
    "                    determined = 1\n",
    "                else:\n",
    "                    errors = [0 - result[0], 1 - result[1]]\n",
    "                    determined = 0\n",
    "\n",
    "                loss = loss + determined * log(result[0]) + (1 - determined) * log(1 - result[0])\n",
    "                self.backpropagation(errors, inputLine)\n",
    "\n",
    "            loss = -1 * loss / len(input)\n",
    "            print(\"Epoch \", e, \" loss = \", loss, \"\\n\")\n",
    "\n",
    "    def predict(self, input):\n",
    "        output = []\n",
    "        for inputItem in input:\n",
    "            probabilities = self.applyAllLayers(inputItem)\n",
    "            if probabilities[0] > probabilities[1]:\n",
    "                output.append(\"YES\")\n",
    "            else:\n",
    "                output.append(\"NO\")\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:29.429648800Z",
     "start_time": "2024-04-19T08:18:29.409692300Z"
    }
   },
   "id": "5ccf945a79c75f02"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:29.566980700Z",
     "start_time": "2024-04-19T08:18:29.564428Z"
    }
   },
   "id": "477aecd1846c49b1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def reshape_data(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    \n",
    "    train_inputs=np.array(train_inputs)\n",
    "    test_inputs=np.array(test_inputs)\n",
    "    test_outputs=np.array(test_outputs)\n",
    "    train_outputs=np.array(train_outputs)\n",
    "    train_inputs = np.array(train_inputs).reshape(-1, 128, 128, 3)  \n",
    "    test_inputs = np.array(test_inputs).reshape(-1, 128, 128, 3)\n",
    "    train_outputs = np.array(train_outputs).flatten()\n",
    "    test_outputs = np.array(test_outputs).flatten()\n",
    "    print(train_inputs.shape,train_outputs.shape,test_inputs.shape,test_outputs.shape)\n",
    "    return train_inputs, train_outputs, test_inputs, test_outputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T09:17:46.920419100Z",
     "start_time": "2024-04-19T09:17:46.901095800Z"
    }
   },
   "id": "53de5060a3b51ed2"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def tang_func(x):\n",
    "    from numpy import tanh\n",
    "    return tanh(x)\n",
    "def with_MyCNN(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    train_inputs, train_outputs, test_inputs, test_outputs = reshape_data(train_inputs, train_outputs, test_inputs, test_outputs)\n",
    "    print(train_inputs.shape, train_outputs.shape, test_inputs.shape, test_outputs.shape)\n",
    "    neuralNetwork = MyCNN()\n",
    "    neuralNetwork.addConvolutionLayer(3, (3, 3))\n",
    "    neuralNetwork.addMaxPoolingLayer((4, 4))\n",
    "    neuralNetwork.addFullyConnectedLayer(15 * 15 * 9, 10, tang_func)\n",
    "    neuralNetwork.addFullyConnectedLayer(10, 2, lambda x: 1 / (1 + exp(-x).real))\n",
    "    neuralNetwork.train(train_inputs, train_outputs)\n",
    "    predicted_outputs = neuralNetwork.predict(test_inputs)\n",
    "    predicted_outputs=[1 if x=='YES' else 0 for x in predicted_outputs]\n",
    "    return predicted_outputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:18:29.870606700Z",
     "start_time": "2024-04-19T08:18:29.869097200Z"
    }
   },
   "id": "b573afea68ade7ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting computed outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98d7af946800eb20"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def with_CNN(train_inputs,train_outputs,test_inputs,test_outputs,output_names=['no_sepia','sepia']):\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    test_inputs = np.array(test_inputs)\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    cnnTool = CNNClass()\n",
    "    cnnTool.train_classifier(train_inputs, train_outputs)\n",
    "    \n",
    "    computed_outputs = cnnTool.get_predicted_data(test_inputs)\n",
    "    return computed_outputs\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:21:14.779201700Z",
     "start_time": "2024-04-19T10:21:14.775214900Z"
    }
   },
   "id": "69765ea9655489da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running experiments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c69c960a14c2719a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def run_cnn_experiments(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    hyperparameters = [\n",
    "        {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.001},\n",
    "        {'epochs': 30, 'batch_size': 32, 'learning_rate': 0.001},\n",
    "        {'epochs': 40, 'batch_size': 64, 'learning_rate': 0.0005},\n",
    "        {'epochs': 50, 'batch_size': 128, 'learning_rate': 0.0005}\n",
    "    ]\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    test_inputs = np.array(test_inputs)\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    results = []\n",
    "    for config in hyperparameters:\n",
    "        cnn = CNNClass()\n",
    "        print(f\"Training with config: {config}\")\n",
    "        cnn.train_classifier(train_inputs, train_outputs, epochs=config['epochs'], batch_size=config['batch_size'], learning_rate=config['learning_rate'])\n",
    "        \n",
    "        predicted_outputs = cnn.get_predicted_data(test_inputs)\n",
    "        accuracy = np.mean(predicted_outputs.flatten() == test_outputs.flatten())\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "        results.append((config, accuracy))\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:21:15.099608500Z",
     "start_time": "2024-04-19T10:21:15.090361900Z"
    }
   },
   "id": "a240592612b5a467"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self, input_dim, num_filters, filter_size, pool_size, output_dim):\n",
    "        self.z_pool_flat = None\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.pool_size = pool_size\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        \n",
    "        conv_output_size = (input_dim[0] - filter_size + 1) // pool_size  # Assuming square filters and square pooling\n",
    "        self.fc_input_dim = conv_output_size * conv_output_size * num_filters\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size, input_dim[2]) * 0.1\n",
    "        self.fc_weights = np.random.randn(self.fc_input_dim, output_dim) * 0.1\n",
    "        self.fc_bias = np.zeros((1, output_dim))\n",
    "\n",
    "    def convolve(self, image, filt):\n",
    "        filter_height, filter_width, num_channels = filt.shape\n",
    "        image_height, image_width, _ = image.shape\n",
    "        out_height = image_height - filter_height + 1\n",
    "        out_width = image_width - filter_width + 1\n",
    "        output = np.zeros((out_height, out_width))\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                output[i, j] = np.sum(image[i:i+filter_height, j:j+filter_width] * filt)\n",
    "        return output\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def max_pool(self, image, size):\n",
    "        pool_height, pool_width = size, size\n",
    "        downsampled_height = image.shape[0] // pool_height\n",
    "        downsampled_width = image.shape[1] // pool_width\n",
    "        output = np.zeros((downsampled_height, downsampled_width))\n",
    "        for i in range(downsampled_height):\n",
    "            for j in range(downsampled_width):\n",
    "                h_start = i * pool_height\n",
    "                w_start = j * pool_width\n",
    "                h_end = h_start + pool_height\n",
    "                w_end = w_start + pool_width\n",
    "                output[i, j] = np.max(image[h_start:h_end, w_start:w_end])\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        z_conv = np.array([[self.convolve(x[n], self.filters[f]) for f in range(self.num_filters)] for n in range(batch_size)])\n",
    "        a_conv = self.relu(z_conv)\n",
    "        z_pool = np.array([[self.max_pool(a_conv[n][f], self.pool_size) for f in range(self.num_filters)] for n in range(batch_size)])\n",
    "        self.z_pool_flat = z_pool.reshape(batch_size, -1)\n",
    "        z_fc = np.dot(self.z_pool_flat, self.fc_weights) + self.fc_bias\n",
    "        a_fc = self.sigmoid(z_fc)\n",
    "        return a_fc\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        x_clipped = np.clip(x, -20, 20)\n",
    "        return 1 / (1 + np.exp(-x_clipped))\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        epsilon = 1e-10  \n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  \n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def train(self, x, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            y_pred = self.forward(x)\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "    \n",
    "            # Ensure y is reshaped to match y_pred if necessary\n",
    "            if y.ndim == 1 or y.shape[1] != y_pred.shape[1]:\n",
    "                y = y.reshape(-1, 1)\n",
    "    \n",
    "            # Gradient of loss w.r.t. final layer output\n",
    "            dL_dz = y_pred - y\n",
    "    \n",
    "            # Gradients of loss w.r.t weights and biases (fully connected layer)\n",
    "            dL_dw = np.dot(self.z_pool_flat.T, dL_dz)  # Check the shapes here\n",
    "            dL_db = np.sum(dL_dz, axis=0, keepdims=True)\n",
    "    \n",
    "            # Update parameters\n",
    "            self.fc_weights -= learning_rate * dL_dw\n",
    "            self.fc_bias -= learning_rate * dL_db\n",
    "    \n",
    "            print(f'Epoch {epoch+1}, Loss: {loss}')\n",
    "            print(\"Gradient shapes:\", dL_dw.shape, self.fc_weights.shape, dL_db.shape, self.fc_bias.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred = self.forward(np.array(x))\n",
    "        predictions = (y_pred > 0.5).astype(np.int32)\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:38:01.069513200Z",
     "start_time": "2024-04-19T10:38:01.051070100Z"
    }
   },
   "id": "29a3aba8989a0899"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def tang_func(x):\n",
    "    from numpy import tanh\n",
    "    return tanh(x)\n",
    "def with_MyCNNd(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    train_inputs, train_outputs, test_inputs, test_outputs = reshape_data(train_inputs, train_outputs, test_inputs, test_outputs)\n",
    "    input_dim = (128, 128, 3)  # Height, Width, Channels\n",
    "    num_filters = 8\n",
    "    filter_size = 3\n",
    "    pool_size = 2\n",
    "    output_dim = 1\n",
    "\n",
    "    model = SimpleCNN(input_dim, num_filters, filter_size, pool_size, output_dim)\n",
    "    model.train(train_inputs,train_outputs,10,0.1)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:37:11.097870500Z",
     "start_time": "2024-04-19T10:37:11.068629500Z"
    }
   },
   "id": "59194fde6d96b8f7"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:21:15.886370Z",
     "start_time": "2024-04-19T10:21:15.873119200Z"
    }
   },
   "id": "7c6b578f192fb2c1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def predict(x,model):\n",
    "    x=np.array(x)\n",
    "    x = np.array(x).reshape(-1, 128, 128, 3)\n",
    "    pred=model.predict(x)\n",
    "    return pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T15:30:04.713660900Z",
     "start_time": "2024-04-19T15:30:04.678938400Z"
    }
   },
   "id": "34f59b13bf0ac4ba"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T10:21:16.065901900Z",
     "start_time": "2024-04-19T10:21:16.060642300Z"
    }
   },
   "id": "abe3eca993796b05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9119113082aaa577"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
