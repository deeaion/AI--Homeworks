{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:11:17.992303Z",
     "start_time": "2024-06-03T04:11:17.816218500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, input_size=49152, hidden_size=12, output_size=10):\n",
    "        self.a1, self.a2, self.z1, self.z2 = None, None, None, None\n",
    "        self.w1 = np.random.randn(hidden_size, input_size) * 0.01\n",
    "        self.w2 = np.random.randn(output_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((hidden_size, 1))\n",
    "        self.b2 = np.zeros((output_size, 1))\n",
    "        self.learning_rate = 0.01\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def relu_derivative(self, z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z))\n",
    "        return exp_z / exp_z.sum(axis=0, keepdims=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(self.w1, x) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.w2, self.a1) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def compute_loss(self, Y):\n",
    "        m = Y.shape[1]\n",
    "        logprobs = np.multiply(np.log(self.a2), Y)\n",
    "        loss = -np.sum(logprobs) / m\n",
    "        return loss\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        m = y.shape[1]\n",
    "        dZ2 = self.a2 - y\n",
    "        dW2 = (1 / m) * np.dot(dZ2, self.a1.T)\n",
    "        db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.dot(self.w2.T, dZ2) * self.relu_derivative(self.z1)\n",
    "        dW1 = (1 / m) * np.dot(dZ1, x.T)\n",
    "        db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        self.w1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.w2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "\n",
    "    def fit(self, X, Y, epochs=1000, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        for i in range(epochs):\n",
    "            self.forward(X)\n",
    "            loss = self.compute_loss(Y)\n",
    "            self.backward(X, Y)\n",
    "            if i % 100 == 0:\n",
    "                print(f'Loss at epoch {i} is {loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.forward(X)\n",
    "        return np.argmax(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deea\\Desktop\\Uni\\By Year\\Second year\\Semester 2\\AI\\Laboratories\\Laboratory_12\\venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:653: FutureWarning: `is_compiling` is deprecated. Use `torch.compiler.is_compiling()` instead.\n",
      "  return dynamo.is_compiling()\n",
      "C:\\Users\\Deea\\Desktop\\Uni\\By Year\\Second year\\Semester 2\\AI\\Laboratories\\Laboratory_12\\venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the data\n",
    "with open('data/gptCodeSnippets.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "codes = [item['code'] for item in data]\n",
    "types = [item['type'] for item in data]\n",
    "\n",
    "# Tokenize the code snippets using CodeBERT tokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "pretrained_codebert_model_dir = './pretrained_codebert_model_3'\n",
    "codebert_tokenizer = RobertaTokenizer.from_pretrained(pretrained_codebert_model_dir)\n",
    "codebert_model = RobertaModel.from_pretrained(pretrained_codebert_model_dir)\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(codes, batch_size=16, max_length=512):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(codes), batch_size):\n",
    "        batch = codes[i:i + batch_size]\n",
    "        inputs = codebert_tokenizer(batch, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "        with torch.no_grad():\n",
    "            outputs = codebert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "    return np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "# Generate embeddings for our codes\n",
    "embeddings = generate_embeddings(codes)\n",
    "\n",
    "# Create label mapping\n",
    "label_to_idx = {label: idx for idx, label in enumerate(set(types))}\n",
    "labels = np.array([label_to_idx[label] for label in types])\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(label_to_idx)\n",
    "labels_one_hot = np.eye(num_classes)[labels].T\n",
    "\n",
    "# Reshape the data\n",
    "def reshape_data(train_inputs, train_outputs, test_inputs, test_outputs):\n",
    "    train_inputs = np.array(train_inputs).reshape(train_inputs.shape[0], -1).T\n",
    "    train_outputs = np.array(train_outputs).reshape(num_classes, -1)\n",
    "    test_inputs = np.array(test_inputs).reshape(test_inputs.shape[0], -1).T\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    return train_inputs, train_outputs, test_inputs, test_outputs\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(embeddings, labels_one_hot.T, test_size=0.2, random_state=42)\n",
    "train_inputs, train_outputs, test_inputs, test_outputs = reshape_data(train_inputs, train_outputs, test_inputs, test_outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:16:00.338372200Z",
     "start_time": "2024-06-03T04:11:18.605805400Z"
    }
   },
   "id": "ad8534680eeb6b67"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 is 3.434043914658668\n",
      "Loss at epoch 100 is 3.4305569336004647\n",
      "Loss at epoch 200 is 3.4257681356411687\n",
      "Loss at epoch 300 is 3.418174784807587\n",
      "Loss at epoch 400 is 3.4091042504756524\n",
      "Loss at epoch 500 is 3.4009570620208476\n",
      "Loss at epoch 600 is 3.391737804672854\n",
      "Loss at epoch 700 is 3.378254077650657\n",
      "Loss at epoch 800 is 3.35872225984241\n",
      "Loss at epoch 900 is 3.332372999705726\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the ANN\n",
    "input_size = train_inputs.shape[0]\n",
    "hidden_size = 23\n",
    "output_size = num_classes\n",
    "\n",
    "ann = ANN(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "ann.fit(train_inputs, train_outputs, epochs=1000, learning_rate=0.01)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:16:01.876135Z",
     "start_time": "2024-06-03T04:16:00.336307300Z"
    }
   },
   "id": "98ba517c1f68c3ea"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['String', 'Math', 'Math', 'String', 'Array', 'Array', 'Array', 'Binary', 'Dynamic Programming', 'Matrix']\n",
      "[19 19 19 19 19 19 19 19 19 19]\n",
      "--------------------------------------------------\n",
      "Code: def last_word_in_alphabetical_order_by_me(text: st...\n",
      "Predicted Class: Binary\n",
      "Real Class: String\n",
      "--------------------------------------------------\n",
      "Code: def compare_real_numbers(a, b):\n",
      "    '''\n",
      "    Functi...\n",
      "Predicted Class: Binary\n",
      "Real Class: Math\n",
      "--------------------------------------------------\n",
      "Code: def problema_3(vector1: list, vector2: list) -> fl...\n",
      "Predicted Class: Binary\n",
      "Real Class: Math\n",
      "--------------------------------------------------\n",
      "Code: def cuvinte_unice(text):\n",
      "    \"\"\"\n",
      "    Găsește cuvin...\n",
      "Predicted Class: Binary\n",
      "Real Class: String\n",
      "--------------------------------------------------\n",
      "Code: def problema_5(sequence:list)->int:\n",
      "    \"\"\"\n",
      "    De...\n",
      "Predicted Class: Binary\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def test_problema_6():\n",
      "    assert (problema_6([2,8...\n",
      "Predicted Class: Binary\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def test_problema7():\n",
      "    assert (problema_7([7,4,...\n",
      "Predicted Class: Binary\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def problema_8_cu_conversie_directa(n):\n",
      "    \"\"\"\n",
      "  ...\n",
      "Predicted Class: Binary\n",
      "Real Class: Binary\n",
      "--------------------------------------------------\n",
      "Code: def get_matrix(n, m) -> list[list[int]]:\n",
      "    \"\"\"\n",
      " ...\n",
      "Predicted Class: Binary\n",
      "Real Class: Dynamic Programming\n",
      "--------------------------------------------------\n",
      "Code: def problema_10(array:list[list]):\n",
      "    \"\"\"\n",
      "       ...\n",
      "Predicted Class: Binary\n",
      "Real Class: Matrix\n"
     ]
    }
   ],
   "source": [
    "# Test the ANN on the provided test data\n",
    "data_to_test_file = 'my_problems_solved/goodFormat.json'\n",
    "with open(data_to_test_file, 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_codes = [item['code'] for item in test_data]\n",
    "test_types = [item['type'] for item in test_data]\n",
    "print(test_types)\n",
    "test_labels = np.array([label_to_idx[label] for label in test_types])\n",
    "\n",
    "# Generate embeddings for the test codes\n",
    "test_embeddings = generate_embeddings(test_codes)\n",
    "test_inputs2 = np.array(test_embeddings).reshape(test_embeddings.shape[0], -1).T\n",
    "\n",
    "# Predict the classes for the test data\n",
    "predicted_classes = ann.predict(test_inputs2)\n",
    "print(predicted_classes)\n",
    "\n",
    "# Print predictions and real classes\n",
    "for i, code in enumerate(test_codes):\n",
    "    print('-' * 50)\n",
    "    print(\"Code:\", code[:50] + '...' if len(code) > 50 else code)\n",
    "    print(\"Predicted Class:\", list(label_to_idx.keys())[predicted_classes[i]])\n",
    "    print(\"Real Class:\", test_types[i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:21:17.770641900Z",
     "start_time": "2024-06-03T04:21:05.895822900Z"
    }
   },
   "id": "eaa3f061f4302e6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8720debb14c68b4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
