{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3754c761f67f8b37"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def quicksort(arr):\n",
      "    \"\"\"\n",
      "    QuickSort algorithm - Sorts a list of integers\n",
      "    params: list of integers\n",
      "    returns: sorted list of integers\n",
      "    \"\"\"\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "Sorting\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load and preprocess the data\n",
    "with open('data/gptCodeSnippets.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "codes = [item['code'] for item in data]\n",
    "types = [item['type'] for item in data]\n",
    "\n",
    "\n",
    "print(codes[0])\n",
    "print(types[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T05:03:27.723269300Z",
     "start_time": "2024-06-03T05:03:27.708415700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.7180190086364746\n",
      "Epoch 2, Loss: 2.1995134353637695\n",
      "Epoch 3, Loss: 2.3755178451538086\n",
      "Epoch 4, Loss: 1.6703535318374634\n",
      "Epoch 5, Loss: 2.5723118782043457\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load and preprocess the data\n",
    "with open('data/gptCodeSnippets.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "codes = [item['code'] for item in data]\n",
    "types = [item['type'] for item in data]\n",
    "\n",
    "# Save the pre-trained CodeBERT model and tokenizer\n",
    "pretrained_codebert_model_dir = './pretrained_codebert_model'\n",
    "if not os.path.exists(pretrained_codebert_model_dir):\n",
    "    codebert_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "    codebert_model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "    codebert_model.save_pretrained(pretrained_codebert_model_dir)\n",
    "    codebert_tokenizer.save_pretrained(pretrained_codebert_model_dir)\n",
    "else:\n",
    "    codebert_tokenizer = RobertaTokenizer.from_pretrained(pretrained_codebert_model_dir)\n",
    "    codebert_model = RobertaModel.from_pretrained(pretrained_codebert_model_dir)\n",
    "\n",
    "# Function to generate embeddings with padding and batching\n",
    "def generate_embeddings(codes, batch_size=16, max_length=512):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(codes), batch_size):\n",
    "        batch = codes[i:i + batch_size]\n",
    "        inputs = codebert_tokenizer(batch, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "        with torch.no_grad():\n",
    "            outputs = codebert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(all_embeddings)\n",
    "\n",
    "# Generate embeddings for our codes\n",
    "embeddings = generate_embeddings(codes)\n",
    "\n",
    "# Create label mapping\n",
    "label_to_idx = {label: idx for idx, label in enumerate(set(types))}\n",
    "labels = torch.tensor([label_to_idx[label] for label in types])\n",
    "\n",
    "class CodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CodeClassifier, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(embeddings, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize classifier and optimizer\n",
    "classifier = CodeClassifier(input_dim=embeddings.size(1), num_classes=len(label_to_idx))\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "fine_tuned_classifier_dir = './fine_tuned_code_classifier'\n",
    "os.makedirs(fine_tuned_classifier_dir, exist_ok=True)\n",
    "\n",
    "# Training loop with evaluation and checkpointing\n",
    "for epoch in range(5):\n",
    "    classifier.train()\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        \n",
    "        outputs = classifier(inputs)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(classifier.state_dict(), os.path.join(fine_tuned_classifier_dir, f'classifier_epoch_{epoch+1}.pt'))\n",
    "\n",
    "# Save the final classifier\n",
    "final_classifier_dir = './final_fine_tuned_code_classifier'\n",
    "os.makedirs(final_classifier_dir, exist_ok=True)\n",
    "torch.save(classifier.state_dict(), os.path.join(final_classifier_dir, 'classifier.pt'))\n",
    "\n",
    "# Function to classify code\n",
    "def classify_code(code):\n",
    "    embedding = generate_embeddings([code])\n",
    "    output = classifier(embedding)\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    return idx_to_label[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T05:05:56.318130900Z",
     "start_time": "2024-06-03T05:03:28.706641600Z"
    }
   },
   "id": "91a37418dc050f5d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Basic Syntax\n"
     ]
    }
   ],
   "source": [
    "example_code = \"\"\"\n",
    "def add(a, b):\n",
    "    return a + b\"\"\"\n",
    "\n",
    "predicted_class = classify_code(example_code)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T05:05:57.430190400Z",
     "start_time": "2024-06-03T05:05:56.317129800Z"
    }
   },
   "id": "cbe011a8cafd98b0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Array\n"
     ]
    }
   ],
   "source": [
    "example_code= \"\"\"def last_word_in_alphabetical_order_by_gpt(text: str):\n",
    "    '''\n",
    "     Returns the last (alphabetically) word that can appear in the text.\n",
    "\n",
    "     :param text: A string containing multiple words separated by spaces.\n",
    "     :return: The last (alphabetically) word in the text.\n",
    "     :time complexity: O(n*log(n)), where n is the number of words in the text.\n",
    "     :space complexity: O(n), where n is the number of words in the text.\n",
    "     '''\n",
    "\n",
    "    words = text.split()  # Split the text into individual words\n",
    "    words.sort()  # Sort the words alphabetically\n",
    "    return words[-1]  # Return the last (alphabetically) word\"\"\"\n",
    "predicted_class = classify_code(example_code)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T05:05:58.466174800Z",
     "start_time": "2024-06-03T05:05:57.429189600Z"
    }
   },
   "id": "6489087b19c52f1d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Code: def last_word_in_alphabetical_order_by_me(text: st...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: String\n",
      "--------------------------------------------------\n",
      "Code: def compare_real_numbers(a, b):\n",
      "    '''\n",
      "    Functi...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Math\n",
      "--------------------------------------------------\n",
      "Code: def problema_3(vector1: list, vector2: list) -> fl...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Math\n",
      "--------------------------------------------------\n",
      "Code: def cuvinte_unice(text):\n",
      "    \"\"\"\n",
      "    Găsește cuvin...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: String\n",
      "--------------------------------------------------\n",
      "Code: def problema_5(sequence:list)->int:\n",
      "    \"\"\"\n",
      "    De...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def test_problema_6():\n",
      "    assert (problema_6([2,8...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def test_problema7():\n",
      "    assert (problema_7([7,4,...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Array\n",
      "--------------------------------------------------\n",
      "Code: def problema_8_cu_conversie_directa(n):\n",
      "    \"\"\"\n",
      "  ...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Binary\n",
      "--------------------------------------------------\n",
      "Code: def get_matrix(n, m) -> list[list[int]]:\n",
      "    \"\"\"\n",
      " ...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Dynamic Programming\n",
      "--------------------------------------------------\n",
      "Code: def problema_10(array:list[list]):\n",
      "    \"\"\"\n",
      "       ...\n",
      "Predicted Class: Data Structures\n",
      "Real Class: Matrix\n"
     ]
    }
   ],
   "source": [
    "data_to_test_file='my_problems_solved/goodFormat.json'\n",
    "with open(data_to_test_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "codes = [item['code'] for item in data]\n",
    "types = [item['type'] for item in data]\n",
    "for code in codes:\n",
    "    print('-'*50)\n",
    "    predicted_class = classify_code(code)\n",
    "    print(\"Code:\", code[:50] + '...' if len(code) > 50 else code)\n",
    "    print(\"Predicted Class:\", predicted_class)\n",
    "    print(\"Real Class:\", types[codes.index(code)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T05:06:22.308908900Z",
     "start_time": "2024-06-03T05:05:58.465169700Z"
    }
   },
   "id": "7ad706e6435ec995"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:21:10.387754600Z",
     "start_time": "2024-06-03T04:21:10.384606300Z"
    }
   },
   "id": "69b9904c1a98ed23"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:21:10.387754600Z",
     "start_time": "2024-06-03T04:21:10.387246300Z"
    }
   },
   "id": "fdd94af5eb340655"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2799e04853f1321"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
